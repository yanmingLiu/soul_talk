import 'dart:async';

import 'package:audioplayers/audioplayers.dart';
import 'package:flutter/material.dart';

/// éŸ³é¢‘å·¥å…·ç±» - æä¾›åŸºç¡€éŸ³é¢‘æ“ä½œåŠŸèƒ½
class AudioPlayManager {
  static AudioContext? _audioContextDefault;

  static Future<void> initAudioPlayer() async {
    await _setupSpeaker();
  }

  /// æ ¼å¼åŒ–éŸ³é¢‘æ—¶é—´æ˜¾ç¤º
  ///
  /// [value] æ—¶é—´å€¼ï¼ˆç§’ï¼‰
  /// è¿”å›æ ¼å¼åŒ–çš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œå¦‚ "1:23" æˆ– "1h2:34"
  static String audioTimer(int value) {
    int hours = value ~/ 3600;
    int minutes = (value % 3600) ~/ 60;
    int seconds = value % 60;

    // ä½¿ç”¨ StringBuffer æ„å»ºå­—ç¬¦ä¸²
    final str = StringBuffer();

    if (hours > 0) {
      str.write('${hours}h');
    }

    // æ ¼å¼åŒ–åˆ†é’Ÿå’Œç§’ï¼Œç¡®ä¿ä¸¤ä½æ•°æ˜¾ç¤º
    str.write('${minutes.toString().padLeft(2, '0')}:');
    str.write(seconds.toString().padLeft(2, '0'));

    return str.toString();
  }

  /// åˆ›å»ºæ–°çš„éŸ³é¢‘æ’­æ”¾å™¨å®ä¾‹
  ///
  /// [playerId] æ’­æ”¾å™¨å”¯ä¸€æ ‡è¯†
  /// è¿”å›é…ç½®å¥½çš„AudioPlayerå®ä¾‹
  static Future<AudioPlayer> createAudioPlayer(String playerId) async {
    final player = AudioPlayer(playerId: playerId);

    // åº”ç”¨å…¨å±€éŸ³é¢‘ä¸Šä¸‹æ–‡é…ç½®
    if (_audioContextDefault != null) {
      await player.setAudioContext(_audioContextDefault!);
    }

    return player;
  }

  /// è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿
  ///
  /// [source] éŸ³é¢‘æº
  /// è¿”å›éŸ³é¢‘æ—¶é•¿ï¼Œè·å–å¤±è´¥æ—¶è¿”å›null
  static Future<Duration?> getAudioDuration(Source source) async {
    try {
      final tempPlayer = AudioPlayer();
      await tempPlayer.setSource(source);
      final duration = await tempPlayer.getDuration();
      await tempPlayer.dispose();
      return duration;
    } catch (e) {
      debugPrint('âš ï¸ AudioUtils: è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: $e');
      return null;
    }
  }

  /// åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡é…ç½®
  static Future<void> _setupSpeaker() async {
    _audioContextDefault = await _getAudioContext();
    await AudioPlayer.global.setAudioContext(_audioContextDefault!);
    debugPrint('ğŸ§ AudioUtils: å…¨å±€éŸ³é¢‘é…ç½®åˆå§‹åŒ–å®Œæˆ');
  }

  /// è·å–å¹³å°ç‰¹å®šçš„éŸ³é¢‘ä¸Šä¸‹æ–‡é…ç½®
  static Future<AudioContext> _getAudioContext() async {
    bool isSpeakerphoneOn = true;

    return AudioContext(
      android: AudioContextAndroid(
        usageType: AndroidUsageType.media,
        audioMode: AndroidAudioMode.normal,
        isSpeakerphoneOn: isSpeakerphoneOn,
      ),
      iOS: AudioContextIOS(
        category: AVAudioSessionCategory.playback,
        options: const {AVAudioSessionOptions.mixWithOthers},
      ),
    );
  }

  /// è·å–å½“å‰å…¨å±€éŸ³é¢‘ä¸Šä¸‹æ–‡
  static AudioContext? get globalAudioContext => _audioContextDefault;
}
